{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb30e7799d6043a28fdf18f479891f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_64d12e83e06143439321137598ab7509",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_78a4bd922a5543cf8a9cfecd764ed961",
              "IPY_MODEL_bcfd02afc9034cd788319c0215b0a02d",
              "IPY_MODEL_35635cc4802d42e491a2af84007de047"
            ]
          }
        },
        "64d12e83e06143439321137598ab7509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78a4bd922a5543cf8a9cfecd764ed961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_22127a85c58247b3bfe5399e324050b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3abef0dff13f470e9e7534c7d5028116"
          }
        },
        "bcfd02afc9034cd788319c0215b0a02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_68dd4a16ed6a4ae7b8f7a6d9bfb29b7c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 371391,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 371391,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7fd69a19ce3419f856c6240ca643c7b"
          }
        },
        "35635cc4802d42e491a2af84007de047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7d2516fbbaa4aa0a86c19ed2cb23f9c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 363k/363k [00:00&lt;00:00, 804kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74f7cfee605e4f519dde33e7e8c34e32"
          }
        },
        "22127a85c58247b3bfe5399e324050b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3abef0dff13f470e9e7534c7d5028116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68dd4a16ed6a4ae7b8f7a6d9bfb29b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7fd69a19ce3419f856c6240ca643c7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7d2516fbbaa4aa0a86c19ed2cb23f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74f7cfee605e4f519dde33e7e8c34e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "591bcc0267324de4a9dfc1455ae9b801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2a33c83832204c4c8b48a4430372d8b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_61e086577df54ecf8098d104c19dd29d",
              "IPY_MODEL_a021d3e39caf47929c955f9c59bde289",
              "IPY_MODEL_09c51ef47a9d426d8ff364d7c32a43b6"
            ]
          }
        },
        "2a33c83832204c4c8b48a4430372d8b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61e086577df54ecf8098d104c19dd29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b64c1ff2223a445c9a95da039b939418",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a75c0cb20ee48748d8d09deee050f03"
          }
        },
        "a021d3e39caf47929c955f9c59bde289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4c35acbf9a3e4d9cbb8aeb789b0c76c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77779,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77779,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9473decea0794160affb50d54b7ce1cb"
          }
        },
        "09c51ef47a9d426d8ff364d7c32a43b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d9559a1dba44947b41384040b4dea65",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 76.0k/76.0k [00:00&lt;00:00, 476kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef25f8aaca38487298dd929213c4fd8d"
          }
        },
        "b64c1ff2223a445c9a95da039b939418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a75c0cb20ee48748d8d09deee050f03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c35acbf9a3e4d9cbb8aeb789b0c76c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9473decea0794160affb50d54b7ce1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d9559a1dba44947b41384040b4dea65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef25f8aaca38487298dd929213c4fd8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "509d942305a5494bb64e30889f84b9aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3380ba531043468fa073deb75226cd73",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab794e2d34fd4d068d16535271863632",
              "IPY_MODEL_c7084eb5e50f425abdaf1d2c8ba445f9",
              "IPY_MODEL_e4b47a657bbe40f6a68418037a76af71"
            ]
          }
        },
        "3380ba531043468fa073deb75226cd73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab794e2d34fd4d068d16535271863632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f01a0ae9f5aa48c9b1dbbd5369601752",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dad50319c6a147a8a135f44f06ce1374"
          }
        },
        "c7084eb5e50f425abdaf1d2c8ba445f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a275b1da66f24fd4beba89b207f2c4df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 51,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 51,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5dde46a42da45c3a9c226a1dde0a9b7"
          }
        },
        "e4b47a657bbe40f6a68418037a76af71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6dad25993e974ec48a4a9a18d36b9a8e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 51.0/51.0 [00:00&lt;00:00, 1.29kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f59e2239bf9b477eb5e3801b5271e0a2"
          }
        },
        "f01a0ae9f5aa48c9b1dbbd5369601752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dad50319c6a147a8a135f44f06ce1374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a275b1da66f24fd4beba89b207f2c4df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5dde46a42da45c3a9c226a1dde0a9b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6dad25993e974ec48a4a9a18d36b9a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f59e2239bf9b477eb5e3801b5271e0a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a94ffe1d369454fb3e3f745cf4af2e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6bccb131a2ee44afac4a6dcf5b3bff98",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5785ae461a714a7a8aa0ea4d96e6bfc6",
              "IPY_MODEL_42231483c3814bb8a185329dd9ca4d5a",
              "IPY_MODEL_02667715e8a5410e8ada47355eec9db3"
            ]
          }
        },
        "6bccb131a2ee44afac4a6dcf5b3bff98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5785ae461a714a7a8aa0ea4d96e6bfc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_827566a11c0a46a4a8c9b1d3099eeec5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4196e59d7a94b2ab188be7630cdaf67"
          }
        },
        "42231483c3814bb8a185329dd9ca4d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_386a11a35b1144cc992e7cf1cebb6899",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 426,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 426,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7034547c14d646b89c0e28a02d15ba9b"
          }
        },
        "02667715e8a5410e8ada47355eec9db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_60564d6ba6734f50a3465da69f2ee070",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 426/426 [00:00&lt;00:00, 9.61kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3f61caf99924bde813d16b8859d55f2"
          }
        },
        "827566a11c0a46a4a8c9b1d3099eeec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4196e59d7a94b2ab188be7630cdaf67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "386a11a35b1144cc992e7cf1cebb6899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7034547c14d646b89c0e28a02d15ba9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60564d6ba6734f50a3465da69f2ee070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3f61caf99924bde813d16b8859d55f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88h2VGmlKUL2",
        "outputId": "d2e4a01e-414e-4c8b-8004-d0a31896e5a2"
      },
      "source": [
        "!pip install torch_optimizer\n",
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install ray"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.1.0-py3-none-any.whl (72 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▌                           | 10 kB 18.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20 kB 20.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 30 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 51 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 61 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 71 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 72 kB 791 kB/s \n",
            "\u001b[?25hCollecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->torch_optimizer) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.1.0\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 10.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.11.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 11.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 40.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 38.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.2\n",
            "Collecting ray\n",
            "  Downloading ray-1.6.0-cp37-cp37m-manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.6 MB 6.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (5.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.0.12)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.2)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.40.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.19.5)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.2.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 543 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray) (1.15.0)\n",
            "Installing collected packages: redis, ray\n",
            "Successfully installed ray-1.6.0 redis-3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIiQvDceKK4V"
      },
      "source": [
        "# ------ LIBRARY -------#\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "import pandas as pd\n",
        "import re\n",
        "import cv2\n",
        "# torch\n",
        "import torch\n",
        "import torch.cuda.amp as amp\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import *\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau, MultiStepLR, OneCycleLR\n",
        "#\n",
        "\n",
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "import torch_optimizer as optim\n",
        "from collections import defaultdict\n",
        "import itertools as it\n",
        "\n",
        "import tqdm\n",
        "import random\n",
        "#import time\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "# transformer\n",
        "from transformers import XLMPreTrainedModel, XLMRobertaModel, XLMRobertaConfig, XLMRobertaTokenizer\n",
        "from transformers import XLMRobertaForSequenceClassification, BertForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import BertForSequenceClassification, DistilBertForSequenceClassification, XLNetForSequenceClassification,\\\n",
        "XLMRobertaForSequenceClassification, XLMForSequenceClassification, RobertaForSequenceClassification\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d02XWDj8KTNn"
      },
      "source": [
        "# class args\n",
        "class args:\n",
        "    # ---- factor ---- #\n",
        "    debug=False\n",
        "    amp = True\n",
        "    gpu = '0'\n",
        "    \n",
        "    epochs=10\n",
        "    batch_size=1\n",
        "    weight_decay=1e-6\n",
        "    n_fold=5\n",
        "    fold=3 # [0, 1, 2, 3, 4] # 원래는 3\n",
        "    \n",
        "    exp_name = 'experiment_name_folder'\n",
        "    dir_ = f'./saved_models/'\n",
        "    pt = 'your_model_name'\n",
        "    max_len = 33\n",
        "    \n",
        "    start_lr = 1e-5#1e-3,5e-5\n",
        "    min_lr=1e-6\n",
        "    # ---- Dataset ---- #\n",
        "\n",
        "    # ---- Else ---- #\n",
        "    num_workers=8\n",
        "    seed=2021\n",
        "    scheduler = None#'get_linear_schedule_with_warmup'\n",
        "\n",
        "\n",
        "data_dir = './'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "##----------------\n",
        "def set_seeds(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False # for faster training, but not deterministic\n",
        "\n",
        "set_seeds(seed=args.seed)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ejfQvDMKi1h"
      },
      "source": [
        "# - util - #\n",
        "def get_learning_rate(optimizer):\n",
        "    lr=[]\n",
        "    for param_group in optimizer.param_groups:\n",
        "        lr +=[ param_group['lr'] ]\n",
        "\n",
        "    assert(len(lr)==1) #we support only one param_group\n",
        "    lr = lr[0]\n",
        "\n",
        "    return lr\n",
        "\n",
        "def load_data():\n",
        "    train=pd.read_csv('./f_train.csv')\n",
        "    test=pd.read_csv('./g_test.csv')\n",
        "    \n",
        "    #\n",
        "    train=train[['title','topic_idx']]\n",
        "    test=test[['title']]\n",
        "    #\n",
        "    \n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "    train['fold'] = -1\n",
        "    for n_fold, (_,v_idx) in enumerate(skf.split(train, train['topic_idx'])):\n",
        "        train.loc[v_idx, 'fold']  = n_fold\n",
        "    train['id'] = [x for x in range(len(train))]\n",
        "    \n",
        "    return train, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmhjAQ5wKkSg"
      },
      "source": [
        "# make KoBertTokenizer\n",
        "import logging\n",
        "import os\n",
        "import unicodedata\n",
        "from shutil import copyfile\n",
        " \n",
        "from transformers import PreTrainedTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW44b0krKnJV"
      },
      "source": [
        "logger = logging.getLogger(__name__)\n",
        " \n",
        "VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n",
        "                     \"vocab_txt\": \"vocab.txt\"}\n",
        " \n",
        "PRETRAINED_VOCAB_FILES_MAP = {\n",
        "    \"vocab_file\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\"\n",
        "    },\n",
        "    \"vocab_txt\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\"\n",
        "    }\n",
        "}\n",
        "\n",
        "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n",
        "    \"monologg/kobert\": 512}\n",
        "\n",
        "PRETRAINED_INIT_CONFIGURATION = {\n",
        "    \"monologg/kobert\": {\"do_lower_case\": False}}\n",
        "\n",
        "SPIECE_UNDERLINE = u'▁'\n",
        "\n",
        "class KoBertTokenizer(PreTrainedTokenizer):\n",
        "    \"\"\"\n",
        "        SentencePiece based tokenizer. Peculiarities:\n",
        "            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n",
        "    \"\"\"\n",
        "    vocab_files_names = VOCAB_FILES_NAMES\n",
        "    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n",
        "    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n",
        "    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n",
        " \n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_file,\n",
        "            vocab_txt,\n",
        "            do_lower_case=False,\n",
        "            remove_space=True,\n",
        "            keep_accents=False,\n",
        "            unk_token=\"[UNK]\",\n",
        "            sep_token=\"[SEP]\",\n",
        "            pad_token=\"[PAD]\",\n",
        "            cls_token=\"[CLS]\",\n",
        "            mask_token=\"[MASK]\",\n",
        "            **kwargs):\n",
        "        super().__init__(\n",
        "            unk_token=unk_token,\n",
        "            sep_token=sep_token,\n",
        "            pad_token=pad_token,\n",
        "            cls_token=cls_token,\n",
        "            mask_token=mask_token,\n",
        "            **kwargs\n",
        "        )\n",
        " \n",
        "        # Build vocab\n",
        "        self.token2idx = dict()\n",
        "        self.idx2token = []\n",
        "        with open(vocab_txt, 'r', encoding='utf-8') as f:\n",
        "            for idx, token in enumerate(f):\n",
        "                token = token.strip()\n",
        "                self.token2idx[token] = idx\n",
        "                self.idx2token.append(token)\n",
        " \n",
        "        #self.max_len_single_sentence = self.max_len - 2  # take into account special tokens\n",
        "        #self.max_len_sentences_pair = self.max_len - 3  # take into account special tokens\n",
        " \n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        " \n",
        "        self.do_lower_case = do_lower_case\n",
        "        self.remove_space = remove_space\n",
        "        self.keep_accents = keep_accents\n",
        "        self.vocab_file = vocab_file\n",
        "        self.vocab_txt = vocab_txt\n",
        " \n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(vocab_file)\n",
        " \n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.idx2token)\n",
        " \n",
        "    def __getstate__(self):\n",
        "        state = self.__dict__.copy()\n",
        "        state[\"sp_model\"] = None\n",
        "        return state\n",
        " \n",
        "    def __setstate__(self, d):\n",
        "        self.__dict__ = d\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(self.vocab_file)\n",
        " \n",
        "    def preprocess_text(self, inputs):\n",
        "        if self.remove_space:\n",
        "            outputs = \" \".join(inputs.strip().split())\n",
        "        else:\n",
        "            outputs = inputs\n",
        "        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n",
        " \n",
        "        if not self.keep_accents:\n",
        "            outputs = unicodedata.normalize('NFKD', outputs)\n",
        "            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n",
        "        if self.do_lower_case:\n",
        "            outputs = outputs.lower()\n",
        " \n",
        "        return outputs\n",
        " \n",
        "    def _tokenize(self, text, return_unicode=True, sample=False):\n",
        "        \"\"\" Tokenize a string. \"\"\"\n",
        "        text = self.preprocess_text(text)\n",
        " \n",
        "        if not sample:\n",
        "            pieces = self.sp_model.EncodeAsPieces(text)\n",
        "        else:\n",
        "            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n",
        "        new_pieces = []\n",
        "        for piece in pieces:\n",
        "            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n",
        "                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n",
        "                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n",
        "                    if len(cur_pieces[0]) == 1:\n",
        "                        cur_pieces = cur_pieces[1:]\n",
        "                    else:\n",
        "                        cur_pieces[0] = cur_pieces[0][1:]\n",
        "                cur_pieces.append(piece[-1])\n",
        "                new_pieces.extend(cur_pieces)\n",
        "            else:\n",
        "                new_pieces.append(piece)\n",
        " \n",
        "        return new_pieces\n",
        " \n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
        "        return self.token2idx.get(token, self.token2idx[self.unk_token])\n",
        " \n",
        "    def _convert_id_to_token(self, index, return_unicode=True):\n",
        "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n",
        "        return self.idx2token[index]\n",
        " \n",
        "    def convert_tokens_to_string(self, tokens):\n",
        "        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n",
        "        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n",
        "        return out_string\n",
        " \n",
        "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
        "        by concatenating and adding special tokens.\n",
        "        A RoBERTa sequence has the following format:\n",
        "            single sequence: [CLS] X [SEP]\n",
        "            pair of sequences: [CLS] A [SEP] B [SEP]\n",
        "        \"\"\"\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        sep = [self.sep_token_id]\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
        " \n",
        "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
        "        \"\"\"\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
        "        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n",
        "        Args:\n",
        "            token_ids_0: list of ids (must not contain special tokens)\n",
        "            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n",
        "                for sequence pairs\n",
        "            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n",
        "                special tokens for the model\n",
        "        Returns:\n",
        "            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n",
        "        \"\"\"\n",
        " \n",
        "        if already_has_special_tokens:\n",
        "            if token_ids_1 is not None:\n",
        "                raise ValueError(\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\n",
        "                    \"ids is already formated with special tokens for the model.\"\n",
        "                )\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n",
        " \n",
        "        if token_ids_1 is not None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
        " \n",
        "    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
        "        A BERT sequence pair mask has the following format:\n",
        "        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "        | first sequence    | second sequence\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
        "        \"\"\"\n",
        "        sep = [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        if token_ids_1 is None:\n",
        "            return len(cls + token_ids_0 + sep) * [0]\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
        " \n",
        "    def save_vocabulary(self, save_directory):\n",
        "        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n",
        "            to a directory.\n",
        "        \"\"\"\n",
        "        if not os.path.isdir(save_directory):\n",
        "            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n",
        "            return\n",
        " \n",
        "        # 1. Save sentencepiece model\n",
        "        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
        " \n",
        "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n",
        "            copyfile(self.vocab_file, out_vocab_model)\n",
        " \n",
        "        # 2. Save vocab.txt\n",
        "        index = 0\n",
        "        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n",
        "        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n",
        "            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n",
        "                if index != token_index:\n",
        "                    logger.warning(\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n",
        "                    )\n",
        "                    index = token_index\n",
        "                writer.write(token + \"\\n\")\n",
        "                index += 1\n",
        " \n",
        "        return out_vocab_model, out_vocab_txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P19TfzuKoAq"
      },
      "source": [
        "def bert_tokenizer(sent, MAX_LEN, tokenizer):\n",
        "    \n",
        "    encoded_dict=tokenizer.encode_plus(\n",
        "    text = sent, \n",
        "    add_special_tokens=True, \n",
        "    max_length=MAX_LEN, \n",
        "    pad_to_max_length=True, \n",
        "    return_attention_mask=True,\n",
        "    truncation = True)\n",
        "    \n",
        "    input_id=encoded_dict['input_ids']\n",
        "    attention_mask=encoded_dict['attention_mask']\n",
        "    #token_type_id = encoded_dict['token_type_ids']\n",
        "    token_type_id = 0\n",
        "    \n",
        "    return input_id, attention_mask, token_type_id\n",
        "\n",
        "def preprocessing_train():\n",
        "    \n",
        "    pt = args.pt#'monologg/kobert'\n",
        "    \n",
        "    if 'kobert' in pt:\n",
        "        tokenizer = KoBertTokenizer.from_pretrained(pt,  cache_dir='bert_ckpt', do_lower_case=False)\n",
        "        print('load kobert')\n",
        "    else:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(args.pt)\n",
        "    \n",
        "    MAX_LEN = args.max_len\n",
        "    train = pd.read_csv('./f_train.csv')\n",
        "    train=train[['title','topic_idx']]\n",
        "\n",
        "    input_ids =[]\n",
        "    attention_masks =[]\n",
        "    token_type_ids =[]\n",
        "    train_data_labels = []\n",
        "\n",
        "    for train_sent, train_label in tqdm.tqdm(zip(train['title'], train['topic_idx'])):\n",
        "        try:\n",
        "            input_id, attention_mask,_ = bert_tokenizer(train_sent, MAX_LEN=MAX_LEN, tokenizer=tokenizer)\n",
        "\n",
        "            input_ids.append(input_id)\n",
        "            attention_masks.append(attention_mask)\n",
        "            token_type_ids.append(0)\n",
        "            #########################################\n",
        "            train_data_labels.append(train_label)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            pass\n",
        "\n",
        "    train_input_ids=np.array(input_ids, dtype=int)\n",
        "    train_attention_masks=np.array(attention_masks, dtype=int)\n",
        "    train_token_type_ids=np.array(token_type_ids, dtype=int)\n",
        "    ###########################################################\n",
        "    train_inputs=(train_input_ids, train_attention_masks, train_token_type_ids)\n",
        "    train_labels=np.asarray(train_data_labels, dtype=np.int32)\n",
        "\n",
        "    # save\n",
        "    train_data = {}\n",
        "\n",
        "    train_data['input_ids'] = train_input_ids\n",
        "    train_data['attention_mask'] = train_attention_masks\n",
        "    train_data['token_type_ids'] = train_token_type_ids\n",
        "    train_data['targets'] = np.asarray(train_data_labels, dtype=np.int32)\n",
        "    \n",
        "    os.makedirs(f'./data/{pt}/', exist_ok=True)\n",
        "    with open(f'./data/{pt}/train_data_{MAX_LEN}.pickle', 'wb') as f:\n",
        "        pickle.dump(train_data, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def preprocessing_test():\n",
        "    \n",
        "    pt = args.pt\n",
        "    if 'kobert' in pt:\n",
        "        tokenizer = KoBertTokenizer.from_pretrained(pt,  cache_dir='bert_ckpt', do_lower_case=False)\n",
        "        print('load kobert')\n",
        "    else:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(args.pt)\n",
        "    MAX_LEN = args.max_len\n",
        "    \n",
        "    test = pd.read_csv('./g_test.csv')\n",
        "    test=test[['title']]\n",
        "    \n",
        "    input_ids =[]\n",
        "    attention_masks =[]\n",
        "    token_type_ids =[]\n",
        "\n",
        "    for test_sent in tqdm.tqdm(test['title']):\n",
        "        try:\n",
        "            input_id, attention_mask,_ = bert_tokenizer(test_sent, MAX_LEN=MAX_LEN, tokenizer=tokenizer)\n",
        "\n",
        "            input_ids.append(input_id)\n",
        "            attention_masks.append(attention_mask)\n",
        "            token_type_ids.append(0)\n",
        "            #########################################\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            pass\n",
        "\n",
        "    test_input_ids=np.array(input_ids, dtype=int)\n",
        "    test_attention_masks=np.array(attention_masks, dtype=int)\n",
        "    test_token_type_ids=np.array(token_type_ids, dtype=int)\n",
        "    ###########################################################\n",
        "    test_inputs=(test_input_ids, test_attention_masks, test_token_type_ids)\n",
        "\n",
        "\n",
        "    # save\n",
        "    test_data = {}\n",
        "\n",
        "    test_data['input_ids'] = test_input_ids\n",
        "    test_data['attention_mask'] = test_attention_masks\n",
        "    test_data['token_type_ids'] = test_token_type_ids\n",
        "    \n",
        "    os.makedirs(f'./data/{pt}/', exist_ok=True)\n",
        "    with open(f'./data/{pt}/test_data_{MAX_LEN}.pickle', 'wb') as f:\n",
        "        pickle.dump(test_data, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2F53OvfsK43l",
        "outputId": "7e7b4672-f94c-4cc7-fbe5-62fcae1f30df"
      },
      "source": [
        "a = pd.read_csv('f_train.csv')\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>topic_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>인천 핀란드 항공기 결항 휴가 철 여행객 분통</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>실리콘밸리 구글 조원 美 전역 거점</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>이란 외무 긴장 완화 해결 책 미국 경제 전쟁 것</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NYT 클린턴 측근 韓 기업 특수 관계 조명 공과 사 종합</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>시진핑 트럼프 중미 무역 협상 조속 타결 희망</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756158</th>\n",
              "      <td>갤폴드 플립 中 구매 기자 만 육박 글로벌 흥행 대감</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756159</th>\n",
              "      <td>속보 아스 트 카 백신 만 회분 내일 공급</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756160</th>\n",
              "      <td>김 대일 PD 도깨비 온 가족 수 게임 개발</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756161</th>\n",
              "      <td>명의 한림대 병원 척추 센터 근육 강화 주사 근거 수술 치료 시기 판단</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756162</th>\n",
              "      <td>코로나 마스크 아이 발달 악 영향 KISTI 과학 향기</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>756163 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          title  topic_idx\n",
              "0                     인천 핀란드 항공기 결항 휴가 철 여행객 분통          4\n",
              "1                           실리콘밸리 구글 조원 美 전역 거점          4\n",
              "2                   이란 외무 긴장 완화 해결 책 미국 경제 전쟁 것          4\n",
              "3              NYT 클린턴 측근 韓 기업 특수 관계 조명 공과 사 종합          4\n",
              "4                     시진핑 트럼프 중미 무역 협상 조속 타결 희망          4\n",
              "...                                         ...        ...\n",
              "756158            갤폴드 플립 中 구매 기자 만 육박 글로벌 흥행 대감          0\n",
              "756159                  속보 아스 트 카 백신 만 회분 내일 공급          0\n",
              "756160                 김 대일 PD 도깨비 온 가족 수 게임 개발          0\n",
              "756161  명의 한림대 병원 척추 센터 근육 강화 주사 근거 수술 치료 시기 판단          0\n",
              "756162           코로나 마스크 아이 발달 악 영향 KISTI 과학 향기          0\n",
              "\n",
              "[756163 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaVIsinrMN3Q"
      },
      "source": [
        "a.dropna().to_csv('f_train.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404,
          "referenced_widgets": [
            "cb30e7799d6043a28fdf18f479891f20",
            "64d12e83e06143439321137598ab7509",
            "78a4bd922a5543cf8a9cfecd764ed961",
            "bcfd02afc9034cd788319c0215b0a02d",
            "35635cc4802d42e491a2af84007de047",
            "22127a85c58247b3bfe5399e324050b2",
            "3abef0dff13f470e9e7534c7d5028116",
            "68dd4a16ed6a4ae7b8f7a6d9bfb29b7c",
            "b7fd69a19ce3419f856c6240ca643c7b",
            "f7d2516fbbaa4aa0a86c19ed2cb23f9c",
            "74f7cfee605e4f519dde33e7e8c34e32",
            "591bcc0267324de4a9dfc1455ae9b801",
            "2a33c83832204c4c8b48a4430372d8b9",
            "61e086577df54ecf8098d104c19dd29d",
            "a021d3e39caf47929c955f9c59bde289",
            "09c51ef47a9d426d8ff364d7c32a43b6",
            "b64c1ff2223a445c9a95da039b939418",
            "1a75c0cb20ee48748d8d09deee050f03",
            "4c35acbf9a3e4d9cbb8aeb789b0c76c6",
            "9473decea0794160affb50d54b7ce1cb",
            "0d9559a1dba44947b41384040b4dea65",
            "ef25f8aaca38487298dd929213c4fd8d",
            "509d942305a5494bb64e30889f84b9aa",
            "3380ba531043468fa073deb75226cd73",
            "ab794e2d34fd4d068d16535271863632",
            "c7084eb5e50f425abdaf1d2c8ba445f9",
            "e4b47a657bbe40f6a68418037a76af71",
            "f01a0ae9f5aa48c9b1dbbd5369601752",
            "dad50319c6a147a8a135f44f06ce1374",
            "a275b1da66f24fd4beba89b207f2c4df",
            "f5dde46a42da45c3a9c226a1dde0a9b7",
            "6dad25993e974ec48a4a9a18d36b9a8e",
            "f59e2239bf9b477eb5e3801b5271e0a2",
            "5a94ffe1d369454fb3e3f745cf4af2e1",
            "6bccb131a2ee44afac4a6dcf5b3bff98",
            "5785ae461a714a7a8aa0ea4d96e6bfc6",
            "42231483c3814bb8a185329dd9ca4d5a",
            "02667715e8a5410e8ada47355eec9db3",
            "827566a11c0a46a4a8c9b1d3099eeec5",
            "e4196e59d7a94b2ab188be7630cdaf67",
            "386a11a35b1144cc992e7cf1cebb6899",
            "7034547c14d646b89c0e28a02d15ba9b",
            "60564d6ba6734f50a3465da69f2ee070",
            "a3f61caf99924bde813d16b8859d55f2"
          ]
        },
        "id": "bM8-oKN-KpG9",
        "outputId": "1e5390ae-5d3b-417d-fb20-5774cb309676"
      },
      "source": [
        "for pt, max_len in zip(['monologg/kobert'],[33]):\n",
        "    args.max_len = max_len\n",
        "    args.pt = pt\n",
        "    preprocessing_train()\n",
        "    preprocessing_test()\n",
        "        \n",
        "    print(f'{args.pt} 모델 전처리 완료')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb30e7799d6043a28fdf18f479891f20",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/363k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "591bcc0267324de4a9dfc1455ae9b801",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/76.0k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "509d942305a5494bb64e30889f84b9aa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a94ffe1d369454fb3e3f745cf4af2e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/426 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'KoBertTokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load kobert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "756088it [02:42, 4653.65it/s]\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'KoBertTokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load kobert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9131/9131 [00:01<00:00, 4860.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "monologg/kobert 모델 전처리 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeEgJrSTKqJZ"
      },
      "source": [
        "# ------------------------\n",
        "#  dataset\n",
        "# ------------------------\n",
        "class KobertDataSet(Dataset):\n",
        "    \n",
        "    def __init__(self, data, test=False):\n",
        "        \n",
        "        self.data = data\n",
        "        self.test = test\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        return self.data['input_ids'].shape[0]\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        \n",
        "        ids = torch.tensor(self.data['input_ids'][idx], dtype=torch.long)\n",
        "        mask = torch.tensor(self.data['attention_mask'][idx], dtype=torch.long)\n",
        "        token_type_ids = torch.tensor(self.data['token_type_ids'][idx], dtype=torch.long)\n",
        "         \n",
        "            \n",
        "        if self.test:\n",
        "            return {\n",
        "                'ids': ids,\n",
        "                'mask': mask,\n",
        "                'token_type_ids': token_type_ids\n",
        "            }\n",
        "        \n",
        "        else:\n",
        "            target = torch.tensor(self.data['targets'][idx],dtype=torch.long)\n",
        "\n",
        "            return {\n",
        "                    'ids': ids,\n",
        "                    'mask': mask,\n",
        "                    'token_type_ids': token_type_ids,\n",
        "                    'targets': target\n",
        "                }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClFDAq2sKs1I"
      },
      "source": [
        "# ------------------------\n",
        "#  scheduler\n",
        "# ------------------------\n",
        "\n",
        "def do_valid(net, valid_loader):\n",
        "\n",
        "    val_loss = 0\n",
        "    target_lst = []\n",
        "    pred_lst = []\n",
        "    logit = []\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    net.eval()\n",
        "    start_timer = timer()\n",
        "    for t, data in enumerate(tqdm.tqdm(valid_loader)):\n",
        "        ids  = data['ids'].to(device)\n",
        "        mask  = data['mask'].to(device)\n",
        "        tokentype = data['token_type_ids'].to(device)\n",
        "        target = data['targets'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if args.amp:\n",
        "                with amp.autocast():\n",
        "                    # output\n",
        "                    output = net(ids, mask)\n",
        "                    output = output[0]\n",
        "\n",
        "                    # loss\n",
        "                    loss = loss_fn(output, target)\n",
        "\n",
        "            else:\n",
        "                output = net(ids, mask)#.squeeze(0)\n",
        "                loss = loss_fn(output, target)\n",
        "            \n",
        "            val_loss += loss\n",
        "            target_lst.extend(target.detach().cpu().numpy())\n",
        "            pred_lst.extend(output.argmax(dim=1).tolist())\n",
        "            logit.extend(output.tolist())\n",
        "            \n",
        "        val_mean_loss = val_loss / len(valid_loader)\n",
        "        validation_score = f1_score(y_true=target_lst, y_pred=pred_lst, average='macro')\n",
        "        validation_acc = accuracy_score(y_true=target_lst, y_pred=pred_lst)\n",
        "        \n",
        "\n",
        "    return val_mean_loss, validation_score, validation_acc, logit\n",
        "\n",
        "def do_predict(net, valid_loader):\n",
        "    \n",
        "    val_loss = 0\n",
        "    pred_lst = []\n",
        "    logit=[]\n",
        "    net.eval()\n",
        "    for t, data in enumerate(tqdm.tqdm(valid_loader)):\n",
        "        ids  = data['ids'].to(device)\n",
        "        mask  = data['mask'].to(device)\n",
        "        tokentype = data['token_type_ids'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if args.amp:\n",
        "                with amp.autocast():\n",
        "                    # output\n",
        "                    output = net(ids, mask)[0]\n",
        "\n",
        "            else:\n",
        "                output = net(ids, mask)\n",
        "             \n",
        "            pred_lst.extend(output.argmax(dim=1).tolist())\n",
        "            logit.extend(output.tolist())\n",
        "            \n",
        "    return pred_lst,logit\n",
        "\n",
        "def run_train(folds=3):\n",
        "    out_dir = args.dir_+ f'/fold{args.fold}/{args.exp_name}/'\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    \n",
        "    # load dataset\n",
        "    train, test = load_data()    \n",
        "    with open(f'./data/{args.pt}/train_data_{args.max_len}.pickle', 'rb') as f:\n",
        "        train_data = pickle.load(f)\n",
        "    with open(f'./data/{args.pt}/test_data_{args.max_len}.pickle', 'rb') as f:\n",
        "        test_data = pickle.load(f)    \n",
        "    \n",
        "    # split fold\n",
        "    for n_fold in range(5):\n",
        "        if n_fold != folds:\n",
        "            print(f'{n_fold} fold pass'+'\\n')\n",
        "            continue\n",
        "            \n",
        "        if args.debug:\n",
        "            train = train.sample(1000).copy()\n",
        "        \n",
        "        trn_idx = train[train['fold']!=n_fold]['id'].values\n",
        "        val_idx = train[train['fold']==n_fold]['id'].values\n",
        "    \n",
        "\n",
        "        train_dict = {'input_ids' : train_data['input_ids'][trn_idx] , 'attention_mask' : train_data['attention_mask'][trn_idx] , \n",
        "                      'token_type_ids' : train_data['token_type_ids'][trn_idx], 'targets' : train_data['targets'][trn_idx]}\n",
        "        val_dict = {'input_ids' : train_data['input_ids'][val_idx] , 'attention_mask' : train_data['attention_mask'][val_idx] , \n",
        "                      'token_type_ids' : train_data['token_type_ids'][val_idx], 'targets' : train_data['targets'][val_idx]}\n",
        "\n",
        "        ## dataset ------------------------------------\n",
        "        train_dataset = KobertDataSet(data = train_dict)\n",
        "        valid_dataset = KobertDataSet(data = val_dict)\n",
        "        trainloader = DataLoader(dataset=train_dataset, batch_size=args.batch_size,\n",
        "                                 num_workers=8, shuffle=True, pin_memory=True)\n",
        "        validloader = DataLoader(dataset=valid_dataset, batch_size=args.batch_size, \n",
        "                                 num_workers=8, shuffle=False, pin_memory=True)\n",
        "\n",
        "        ## net ----------------------------------------\n",
        "        scaler = amp.GradScaler()\n",
        "        if 'xlm-roberta' in args.pt:\n",
        "            net = XLMRobertaForSequenceClassification.from_pretrained(args.pt, num_labels = 7) \n",
        "        \n",
        "        elif 'klue/roberta' in args.pt:\n",
        "            net = RobertaForSequenceClassification.from_pretrained(args.pt, num_labels = 7) \n",
        "        else:\n",
        "            net = BertForSequenceClassification.from_pretrained(args.pt, num_labels = 7) \n",
        "\n",
        "        net.to(device)\n",
        "        if len(args.gpu)>1:\n",
        "            net = nn.DataParallel(net)\n",
        "\n",
        "        # ------------------------\n",
        "        # loss\n",
        "        # ------------------------\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        # ------------------------\n",
        "        #  Optimizer\n",
        "        # ------------------------\n",
        "        optimizer = optim.Lookahead(optim.RAdam(filter(lambda p: p.requires_grad,net.parameters()), lr=args.start_lr), alpha=0.5, k=5)\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = len(trainloader)*args.epochs)\n",
        "        \n",
        "        \n",
        "        # ----\n",
        "        start_timer = timer()\n",
        "        best_score = 0\n",
        "\n",
        "        for epoch in range(1, args.epochs+1):\n",
        "            train_loss = 0\n",
        "            valid_loss = 0\n",
        "\n",
        "            target_lst = []\n",
        "            pred_lst = []\n",
        "            lr = get_learning_rate(optimizer)\n",
        "            print(f'-------------------')\n",
        "            print(f'{epoch}epoch start')\n",
        "            print(f'-------------------'+'\\n')\n",
        "            print(f'learning rate : {lr : .6f}')\n",
        "            for t, data in enumerate(tqdm.tqdm(trainloader)):\n",
        "\n",
        "                # one iteration update  -------------\n",
        "                ids  = data['ids'].to(device)\n",
        "                mask  = data['mask'].to(device)\n",
        "                tokentype = data['token_type_ids'].to(device)\n",
        "                target = data['targets'].to(device)\n",
        "\n",
        "                # ------------\n",
        "                net.train()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "\n",
        "                if args.amp:\n",
        "                    with amp.autocast():\n",
        "                        # output\n",
        "                        output = net(ids, mask)\n",
        "                        output = output[0]\n",
        "\n",
        "                        # loss\n",
        "                        loss = loss_fn(output, target)\n",
        "                        train_loss += loss\n",
        "\n",
        "\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "\n",
        "                else:\n",
        "                    # output\n",
        "                    output = net(ids, mask)\n",
        "\n",
        "                    # loss\n",
        "                    loss = loss_fn(output, target)\n",
        "                    train_loss += loss\n",
        "\n",
        "                    # update\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "\n",
        "                # for calculate f1 score\n",
        "                target_lst.extend(target.detach().cpu().numpy())\n",
        "                pred_lst.extend(output.argmax(dim=1).tolist())\n",
        "\n",
        "\n",
        "                if scheduler is not None:\n",
        "                    scheduler.step() \n",
        "            train_loss = train_loss / len(trainloader)\n",
        "            train_score = f1_score(y_true=target_lst, y_pred=pred_lst, average='macro')\n",
        "            train_acc = accuracy_score(y_true=target_lst, y_pred=pred_lst)\n",
        "\n",
        "            # validation\n",
        "            valid_loss, valid_score, valid_acc, _ = do_valid(net, validloader)\n",
        "\n",
        "\n",
        "            if valid_acc > best_score:\n",
        "                best_score = valid_acc\n",
        "                best_epoch = epoch\n",
        "                best_loss = valid_loss\n",
        "\n",
        "                torch.save(net.state_dict(), out_dir + f'/{folds}f_{epoch}e_{best_score:.4f}_s.pth')\n",
        "                print('best model saved'+'\\n')\n",
        "\n",
        "\n",
        "            print(f'train loss : {train_loss:.4f}, train f1 score : {train_score : .4f}, train acc : {train_acc : .4f}'+'\\n')\n",
        "            print(f'valid loss : {valid_loss:.4f}, valid f1 score : {valid_score : .4f}, valid acc : {valid_acc : .4f}'+'\\n')\n",
        "\n",
        "\n",
        "        print(f'best valid loss : {best_loss : .4f}'+'\\n')\n",
        "        print(f'best epoch : {best_epoch }'+'\\n')\n",
        "        print(f'best accuracy : {best_score : .4f}'+'\\n')\n",
        "        \n",
        "def run_predict(model_path):\n",
        "    ## dataset ------------------------------------\n",
        "    # load\n",
        "    with open(f'./data/{args.pt}/test_data_{args.max_len}.pickle', 'rb') as f:\n",
        "        test_dict = pickle.load(f)\n",
        "        \n",
        "    print('test load')\n",
        "    test_dataset = KobertDataSet(data = test_dict, test=True)\n",
        "    testloader = DataLoader(dataset=test_dataset, batch_size=args.batch_size, \n",
        "                             num_workers=8, shuffle=False, pin_memory=True)\n",
        "    print('set testloader')\n",
        "    ## net ----------------------------------------\n",
        "    scaler = amp.GradScaler()\n",
        "    if 'xlm-roberta' in args.pt:\n",
        "        net = XLMRobertaForSequenceClassification.from_pretrained(args.pt, num_labels = 7) \n",
        "        \n",
        "    elif 'klue/roberta' in args.pt:\n",
        "        net = RobertaForSequenceClassification.from_pretrained(args.pt, num_labels = 7) \n",
        "    else:\n",
        "        net = BertForSequenceClassification.from_pretrained(args.pt, num_labels = 7) \n",
        "        \n",
        "    net.to(device)\n",
        "    \n",
        "    if len(args.gpu)>1:\n",
        "        net = nn.DataParallel(net)\n",
        "\n",
        "    f = torch.load(model_path)\n",
        "    net.load_state_dict(f, strict=True)  # True\n",
        "    print('load saved models')\n",
        "    # ------------------------\n",
        "    # validation\n",
        "    preds, logit = do_predict(net, testloader) #outputs\n",
        "           \n",
        "    print('complete predict')\n",
        "    \n",
        "    return preds, np.array(logit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "fUUT4OegPQs_",
        "outputId": "0ad36570-dcb4-4575-edaf-84590d2856f7"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class Network(object):\n",
        "    def __init__(self, lr=0.01, momentum=0.5):\n",
        "        use_cuda = torch.cuda.is_available()\n",
        "        self.device = device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "        self.train_loader, self.test_loader = dataset_creator(use_cuda)\n",
        "\n",
        "        self.model = Model().to(device)\n",
        "        self.optimizer = optim.SGD(\n",
        "            self.model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    def train(self):\n",
        "        train(self.model, self.device, self.train_loader, self.optimizer)\n",
        "        return test(self.model, self.device, self.test_loader)\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.model.state_dict()\n",
        "\n",
        "    def set_weights(self, weights):\n",
        "        self.model.load_state_dict(weights)\n",
        "\n",
        "    def save(self):\n",
        "        torch.save(self.model.state_dict(), \"mnist_cnn.pt\")\n",
        "\n",
        "\n",
        "net = Network()\n",
        "net.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e6c0214dad7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-e6c0214dad7c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lr, momentum)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset_creator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "0dNvUKHAOSyn",
        "outputId": "a850ee5d-a28d-47f6-f746-8384a06634ae"
      },
      "source": [
        "import ray\n",
        "ray.init()\n",
        "\n",
        "RemoteNetwork = ray.remote(Network)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
            "  warnings.warn(warning_message)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-f1f457960482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mRemoteNetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Network' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG__45mvOeBU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G53dMXuXOd_K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6EB348aOd8z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcCIyGc_Od6x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uduH2eGKtyP"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    for pt, max_len in zip(['monologg/kobert'],[33]):\n",
        "        \n",
        "        args.max_len = max_len\n",
        "        args.pt = pt\n",
        "        args.exp_name = str(args.pt) + '_' + str(args.max_len)\n",
        "        \n",
        "        for i in [0,1,2,3,4]: # 5fold\n",
        "            run_train(folds=i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuNdI-qbKvH6"
      },
      "source": [
        "def ensemble():\n",
        "    final_logit=0\n",
        "    args.max_len=33\n",
        "    args.pt = 'monologg/kobert'\n",
        "    _, logit1 = run_predict(\"./saved_models/fold3/kobert/0f_9e_0.8895_s.pth\")\n",
        "    _, logit2 = run_predict(\"./saved_models/fold3/kobert/1f_10e_0.8823_s.pth\")\n",
        "    _, logit3 = run_predict(\"./saved_models/fold3/kobert/2f_8e_0.8888_s.pth\")\n",
        "    _, logit4 = run_predict(\"./saved_models/fold3/kobert/3f_10e_0.8897_s.pth\")\n",
        "    _, logit5 = run_predict(\"./saved_models/fold3/kobert/4f_8e_0.8867_s.pth\")\n",
        "    final_logit += (logit1+logit2+logit3+logit4+logit5)/5\n",
        "        \n",
        "    return final_logit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNI6g-tSLFBz"
      },
      "source": [
        "final_logit = ensemble()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF4s4siLLGlP"
      },
      "source": [
        "sub = pd.read_csv(\"./sample_submission.csv\")\n",
        "sub['topic_idx'] = final_logit.argmax(1)\n",
        "# preds\n",
        "sub.to_csv('./submission/final_submission.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}